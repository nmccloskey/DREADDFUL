
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
DREADDFUL: Group Differences under Cell-Count Thresholds
========================================================
Tests for statistical differences in **cell count**, **coverage**, and **dispersion**
across experimental groups under a range of inclusion thresholds based on the
minimum number of fluorescently labeled (e.g., mCherry+) cells.

Default thresholds: 50, 100, 150, 200

Usage (CLI):
------------
python dreaddful_group_tests.py \
  --csv animal_metrics.csv \
  --outdir results/ \
  --id-col animal \
  --group-col group \
  --count-col n_cells_total \
  --coverage-cols coverage_mean \
  --dispersion-cols dispersion_mean \
  --thresholds 50 100 150 200

Notes:
------
- The script auto-detects coverage/dispersion columns if not provided:
  any numeric column with "coverage" in its name → coverage;
  any numeric column with "dispersion", "ripley", "moran" in its name → dispersion.
- Statistical plan per metric:
  • Check normality within groups (Shapiro–Wilk, n≥3) and homogeneity (Levene).
  • If all groups normal & homoscedastic → one-way ANOVA + pairwise t-tests (Holm-adjusted).
  • Otherwise → Kruskal–Wallis + pairwise Mann–Whitney U (Holm-adjusted).
- Effect sizes:
  • ANOVA: eta² from F-statistic.
  • Kruskal–Wallis: epsilon² approximation.
  • Pairwise t-test: Hedges' g.
  • Pairwise Mann–Whitney: Cliff’s delta.
- Outputs per threshold (written to --outdir/threshold_{T}/):
  • summary.csv — group Ns and descriptives
  • omnibus.csv — omnibus test per metric
  • pairwise.csv — pairwise posthocs per metric
  • figures/*.png — boxplots per metric

Author: Nick McCloskey
The initial structure for this script was generated by ChatGPT (OpenAI, version 5, Aug 2025),
then adapted and refined by the author for specific project needs.
"""
import argparse
import logging
from pathlib import Path
from typing import List, Dict, Tuple
import numpy as np
import pandas as pd
from scipy import stats
import itertools
import math
import warnings
import matplotlib.pyplot as plt

# -------------------------------
# Utilities
# -------------------------------

def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s | %(levelname)s | %(message)s"
    )

def holm_adjust(pvals: List[float]) -> List[float]:
    """Holm–Bonferroni step-down correction."""
    m = len(pvals)
    order = np.argsort(pvals)
    adjusted = np.empty(m, dtype=float)
    for rank, idx in enumerate(order):
        adjusted[idx] = min(1.0, max((m - rank) * pvals[idx], (adjusted[order[rank - 1]] if rank > 0 else 0)))
    # ensure monotonic non-decreasing after ordering
    # re-apply to preserve ordering property
    sorted_adj = np.minimum.accumulate(adjusted[order][::-1])[::-1]
    out = np.empty(m, dtype=float)
    out[order] = sorted_adj
    return out.tolist()

def hedges_g(x: np.ndarray, y: np.ndarray) -> float:
    """Hedges' g (bias-corrected Cohen's d)."""
    nx, ny = len(x), len(y)
    if nx < 2 or ny < 2:
        return np.nan
    sx2, sy2 = np.var(x, ddof=1), np.var(y, ddof=1)
    sp2 = ((nx - 1) * sx2 + (ny - 1) * sy2) / (nx + ny - 2)
    if sp2 <= 0:
        return np.nan
    d = (np.mean(x) - np.mean(y)) / math.sqrt(sp2)
    # small-sample correction
    J = 1 - (3 / (4*(nx + ny) - 9))
    return J * d

def cliffs_delta(x: np.ndarray, y: np.ndarray) -> float:
    """Cliff’s delta for two independent samples."""
    # Efficient computation using sorting
    x_sorted = np.sort(x)
    y_sorted = np.sort(y)
    m, n = len(x_sorted), len(y_sorted)
    i = j = more = less = 0
    while i < m and j < n:
        if x_sorted[i] > y_sorted[j]:
            more += (m - i)
            j += 1
        elif x_sorted[i] < y_sorted[j]:
            less += (n - j)
            i += 1
        else:
            # handle ties: advance both
            i += 1; j += 1
    return (more - less) / (m * n) if m > 0 and n > 0 else np.nan

def epsilon_squared_kruskal(H: float, k: int, N: int) -> float:
    """Epsilon-squared effect size for Kruskal–Wallis (Tomczak & Tomczak, 2014)."""
    if N <= 0 or k <= 1:
        return np.nan
    return (H - k + 1) / (N - k)

def eta_squared_from_F(F: float, df1: int, df2: int) -> float:
    """Eta-squared from ANOVA F-statistic and dfs."""
    if F is None or df1 is None or df2 is None or (F*df1 + df2) == 0:
        return np.nan
    return (F * df1) / (F * df1 + df2)

def detect_metric_columns(df: pd.DataFrame,
                          coverage_cols: List[str],
                          dispersion_cols: List[str],
                          count_col: str) -> Tuple[List[str], List[str]]:
    """Auto-detect coverage/dispersion columns if not explicitly provided."""
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    cov = coverage_cols or [c for c in numeric_cols if ("coverage" in c.lower() or "density" in c.lower()) and c != count_col]
    disp = dispersion_cols or [c for c in numeric_cols if any(k in c.lower() for k in ["dispersion", "ripley", "moran", "entropy", "evenness"])]
    return cov, disp

def check_normality_groups(df: pd.DataFrame, group_col: str, value_col: str) -> bool:
    """Return True if **all** groups appear normal by Shapiro–Wilk (alpha=.05), only tested for groups with n>=3."""
    groups = [g[1][value_col].dropna().values for g in df.groupby(group_col)]
    flags = []
    for arr in groups:
        if len(arr) >= 3:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                stat, p = stats.shapiro(arr)
            flags.append(p > 0.05)
        else:
            # if too small, treat as 'unknown normality' → require all others to be normal
            flags.append(True)
    return all(flags) if len(flags) > 0 else False

def check_homoscedasticity(df: pd.DataFrame, group_col: str, value_col: str) -> bool:
    """Levene's test (center=median) for equal variances across groups (alpha=.05)."""
    arrays = [g[1][value_col].dropna().values for g in df.groupby(group_col)]
    if len(arrays) < 2:
        return True
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        stat, p = stats.levene(*arrays, center='median')
    return p > 0.05

def omnibus_and_posthoc(df: pd.DataFrame, group_col: str, value_col: str) -> Tuple[Dict, pd.DataFrame]:
    """
    Run omnibus test with decision logic, then pairwise posthocs.
    Returns:
      omnibus: dict with test, statistic, df, p, effect
      pairwise_df: rows of pairwise comparisons with p-raw, p-holm, effect size
    """
    gb = list(df.groupby(group_col, sort=True)) 
    labels = [str(name) for name, _ in gb]
    groups = [sub[value_col].dropna().values for _, sub in gb]

    N = sum(len(a) for a in groups)
    k = len(groups)

    normal = check_normality_groups(df, group_col, value_col)
    homo = check_homoscedasticity(df, group_col, value_col)

    omnibus = {"metric": value_col, "test": None, "statistic": np.nan, "df1": np.nan, "df2": np.nan, "p": np.nan, "effect": np.nan,
               "assumptions": f"normal={normal}, homoscedastic={homo}"}
    pair_rows = []

    if k < 2 or any(len(a) == 0 for a in groups):
        return omnibus, pd.DataFrame(columns=["metric","g1","g2","test","statistic","p_raw","p_holm","effect"])

    if normal and homo:
        # One-way ANOVA
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            F, p = stats.f_oneway(*groups)
        df1 = k - 1
        df2 = N - k
        eta2 = eta_squared_from_F(F, df1, df2)
        omnibus.update({"test": "ANOVA", "statistic": F, "df1": df1, "df2": df2, "p": p, "effect": eta2})
        # Pairwise t-tests (pooled if homo else Welch—but we only reach here if homo True)
        pvals = []
        comps = []
        stats_list = []
        effects = []
        for (i, g1), (j, g2) in itertools.combinations(list(enumerate(groups)), 2):
            t, p_ = stats.ttest_ind(g1, g2, equal_var=True, nan_policy='omit')
            pvals.append(p_)
            comps.append((labels[i], labels[j]))
            stats_list.append(t)
            effects.append(hedges_g(g1, g2))
        if pvals:
            p_holm = holm_adjust(pvals)
            for (a,b), tval, pr, ph, eff in zip(comps, stats_list, pvals, p_holm, effects):
                pair_rows.append({"metric": value_col, "g1": a, "g2": b, "test": "t-test (pooled)", "statistic": tval,
                                  "p_raw": pr, "p_holm": ph, "effect": eff})
    else:
        # Kruskal–Wallis
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            H, p = stats.kruskal(*groups)
        eps2 = epsilon_squared_kruskal(H, k, N)
        omnibus.update({"test": "Kruskal–Wallis", "statistic": H, "df1": k-1, "df2": np.nan, "p": p, "effect": eps2})
        # Pairwise Mann–Whitney U
        pvals = []
        comps = []
        stats_list = []
        effects = []
        for (i, g1), (j, g2) in itertools.combinations(list(enumerate(groups)), 2):
            # Use two-sided, 'asymptotic' by default
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                U, p_ = stats.mannwhitneyu(g1, g2, alternative='two-sided')
            pvals.append(p_)
            comps.append((labels[i], labels[j]))
            stats_list.append(U)
            effects.append(cliffs_delta(g1, g2))
        if pvals:
            p_holm = holm_adjust(pvals)
            for (a,b), Uval, pr, ph, eff in zip(comps, stats_list, pvals, p_holm, effects):
                pair_rows.append({"metric": value_col, "g1": a, "g2": b, "test": "Mann–Whitney U", "statistic": Uval,
                                  "p_raw": pr, "p_holm": ph, "effect": eff})

    return omnibus, pd.DataFrame(pair_rows)

def describe_by_group(df: pd.DataFrame, group_col: str, metrics: List[str]) -> pd.DataFrame:
    out = []
    for grp, sub in df.groupby(group_col):
        row = {"group": grp, "N": len(sub)}
        for m in metrics:
            vals = sub[m].dropna().values
            row[f"{m}_mean"] = np.mean(vals) if len(vals) else np.nan
            row[f"{m}_sd"] = np.std(vals, ddof=1) if len(vals) > 1 else np.nan
            row[f"{m}_median"] = np.median(vals) if len(vals) else np.nan
        out.append(row)
    return pd.DataFrame(out).sort_values("group")

def run_analysis(csv: Path,
                 outdir: Path,
                 id_col: str,
                 group_col: str,
                 count_col: str,
                 coverage_cols: List[str],
                 dispersion_cols: List[str],
                 thresholds: List[int]) -> None:
    outdir.mkdir(parents=True, exist_ok=True)
    df = pd.read_csv(csv)

    # Basic checks
    for col in [id_col, group_col, count_col]:
        if col not in df.columns:
            raise ValueError(f"Required column '{col}' not found. Available: {list(df.columns)}")

    # Auto-detect metrics if not provided
    coverage_cols, dispersion_cols = detect_metric_columns(df, coverage_cols, dispersion_cols, count_col)

    logging.info(f"Detected coverage columns: {coverage_cols}")
    logging.info(f"Detected dispersion columns: {dispersion_cols}")

    metrics = [count_col] + coverage_cols + dispersion_cols

    # Iterate thresholds
    for T in thresholds:
        sub = df[df[count_col] >= T].copy()
        tdir = outdir / f"threshold_{T}"
        tdir.mkdir(parents=True, exist_ok=True)

        logging.info(f"Threshold {T}: kept {len(sub)} of {len(df)} animals. Groups: {sub[group_col].value_counts().to_dict()}")

        # Descriptives
        summary = describe_by_group(sub, group_col, metrics)
        summary.to_csv(tdir / "summary.csv", index=False)

        # Omnibus and pairwise for each metric
        omni_rows = []
        all_pairs = []
        for m in metrics:
            if sub[group_col].nunique() < 2:
                logging.warning(f"Threshold {T}, metric {m}: <2 groups present; skipping stats.")
                continue
            omnibus, pairwise = omnibus_and_posthoc(sub[[group_col, m]].dropna(), group_col, m)
            omni_rows.append(omnibus)
            if not pairwise.empty:
                all_pairs.append(pairwise)

            # Figure
            plt.figure()
            # Single chart per metric
            gb = list(sub.groupby(group_col, sort=True))
            data_to_plot = [subg[m].dropna().values for _, subg in gb]
            labels = [str(name) for name, _ in gb]
            plt.boxplot(data_to_plot, labels=labels, showmeans=True)
            plt.title(f"{m} by {group_col} (T≥{T})")
            plt.ylabel(m)
            plt.xlabel(group_col)
            fig_path = tdir / f"{m}_boxplot.png"
            plt.tight_layout()
            plt.savefig(fig_path, dpi=200)
            plt.close()

        pd.DataFrame(omni_rows).to_csv(tdir / "omnibus.csv", index=False)
        if all_pairs:
            pd.concat(all_pairs, ignore_index=True).to_csv(tdir / "pairwise.csv", index=False)

    # Overall index
    (outdir / "DONE.txt").write_text("Analysis complete.\n")

def parse_args():
    p = argparse.ArgumentParser(description="DREADDFUL group-differences analysis under cell-count thresholds.")
    p.add_argument("--csv", type=Path, required=True, help="Input CSV of per-animal metrics.")
    p.add_argument("--outdir", type=Path, required=True, help="Output directory.")
    p.add_argument("--id-col", type=str, default="animal", help="Animal identifier column.")
    p.add_argument("--group-col", type=str, default="group", help="Group column (e.g., Gi, Gq, mC).")
    p.add_argument("--count-col", type=str, default="n_cells_total", help="Total fluorescent cell count column.")
    p.add_argument("--coverage-cols", nargs="*", default=None, help="Coverage metric columns (auto-detected if omitted).")
    p.add_argument("--dispersion-cols", nargs="*", default=None, help="Dispersion metric columns (auto-detected if omitted).")
    p.add_argument("--thresholds", nargs="*", type=int, default=[50, 100, 150, 200], help="Minimum cell-count thresholds to evaluate.")
    return p.parse_args()

def main():
    setup_logging()
    args = parse_args()
    run_analysis(csv=args.csv,
                 outdir=args.outdir,
                 id_col=args.id_col,
                 group_col=args.group_col,
                 count_col=args.count_col,
                 coverage_cols=args.coverage_cols,
                 dispersion_cols=args.dispersion_cols,
                 thresholds=args.thresholds)

if __name__ == "__main__":
    main()
