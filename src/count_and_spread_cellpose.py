#!/usr/bin/env python3

"""
count_and_spread_cellpose.py  —  minimal Cellpose v4 (SAM) pipeline

- Use red channel by default (mCherry).
- Let CP normalize and estimate diameter automatically (diameter=None).
- Keep post-filters OFF by default to avoid undercounting; enable via config if needed.

Install:
  pip install "cellpose[all]" scikit-image pandas matplotlib tqdm pillow joblib

Run:
  python count_and_spread_cellpose.py --meta metadata.csv --out out_dir --config config_cellpose.json --gpu --jobs 1

Author: Nick McCloskey
The initial structure for this script was generated by ChatGPT (OpenAI, version 5, Aug 2025),
then adapted and refined by the author for specific project needs.
"""

import argparse, os, warnings, traceback
from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

from PIL import Image, ImageOps
from skimage import io
from skimage.measure import regionprops, label, find_contours
from scipy.spatial import ConvexHull
from tqdm.auto import tqdm

# Cellpose v4
from cellpose import models

try:
    from joblib import Parallel, delayed
    HAVE_JOBLIB = True
except Exception:
    HAVE_JOBLIB = False

# ----------------- IO & helpers -----------------

def imread_any(path):
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        im = Image.open(path)
        # honor EXIF orientation just in case
        im = ImageOps.exif_transpose(im)
        return np.array(im)

MASK_EXTS = (".tif", ".tiff", ".png", ".jpg", ".jpeg")

def guess_mask_for_slice(slice_path, provided=None):
    if provided and isinstance(provided, str) and provided.strip() and os.path.exists(provided):
        return provided
    p = Path(slice_path)
    search_dirs = [p.parent, p.parent / "masks", p.parent / "Masks"]
    candidates = []
    for d in search_dirs:
        for ext in MASK_EXTS:
            candidates.append(d / f"{p.stem}_mask{ext}")
    for c in candidates:
        if c.exists():
            return str(c)
    raise FileNotFoundError(f"No mask found for slice '{slice_path}'. Tried: {', '.join(map(str, candidates))}")

def convex_hull_ratio(centroids, mask):
    if len(centroids) < 3:
        return 0.0
    hull = ConvexHull(centroids)
    hull_area = hull.volume
    mask_area = float(mask.sum())
    return (hull_area / mask_area) if mask_area > 0 else 0.0

def save_qc_overlay(img_gray, roi_mask, centroids, out_png):
    plt.figure(figsize=(6,6))
    plt.imshow(img_gray, cmap='gray')
    cs = find_contours(roi_mask.astype(float), 0.5)
    for c in cs:
        plt.plot(c[:,1], c[:,0], linewidth=1)
    if len(centroids):
        plt.scatter(centroids[:,1], centroids[:,0], s=10)
    plt.axis('off'); plt.tight_layout()
    plt.savefig(out_png, dpi=300)
    plt.close()

# ----------------- config -----------------

def load_config(path):
    """Load JSON config, allowing per-group overrides.

    Schema (example):
    {
      "default": {
        "pretrained_model": "cpsam",
        "diameter": 0,
        "cellprob_threshold": -0.5,
        "flow_threshold": 0.2,
        "normalize": true,
        "min_area": 0,
        "max_area": 0,
        "eccentricity_max": 1.0,
        "solidity_min": 0.0,
        "min_size": 0,               # will be used for CP and/or post-filter
        "max_size_fraction": 0.0,     # fraction of ROI area for dynamic max area
        "niter": "auto",             # CP iteration count (if supported)
        "tile_overlap": 0.0           # overlap for tiled eval (if supported)
      },
      "Gi": { "cellprob_threshold": -1.0 }
    }
    """
    cfg = {
        "default": {
            "pretrained_model": "cpsam",  # "cpsam" (v4 default) or "cyto2" / "nuclei"
            "diameter": 0,                # 0/None => let CP estimate
            "cellprob_threshold": -0.5,   # more sensitive; raise toward 0 to be stricter
            "flow_threshold": 0.2,        # lenient to avoid missing weak cells
            "normalize": True,            # let CP normalize internally
            # Post-filtering (OFF by default to avoid undercounting)
            "min_area": 0,
            "max_area": 0,
            "eccentricity_max": 1.0,
            "solidity_min": 0.0,
            # NEW — Calibrated extras
            "min_size": 0,
            "max_size_fraction": 0.0,
            "niter": "auto",
            "tile_overlap": 0.0
        }
    }
    if path and os.path.exists(path):
        import json
        with open(path, "r", encoding="utf-8") as f:
            user = json.load(f)
        for k,v in user.items():
            if k == "default":
                cfg["default"].update(v)
            else:
                cfg[k] = v
    return cfg

# ----------------- post-filtering -----------------

def post_filter_labels(labels, min_area=0, max_area=0, eccentricity_max=1.0, solidity_min=0.0):
    if labels.max() == 0:
        return labels
    props = regionprops(labels)
    keep = np.ones(len(props)+1, dtype=bool)  # index 0 unused
    for i, p in enumerate(props, start=1):
        if min_area and p.area < min_area: keep[i] = False; continue
        if max_area and p.area > max_area: keep[i] = False; continue
        if eccentricity_max < 1.0 and getattr(p, "eccentricity", 0.0) > eccentricity_max: keep[i] = False; continue
        if solidity_min > 0.0 and getattr(p, "solidity", 1.0) < solidity_min: keep[i] = False; continue
    out = np.zeros_like(labels)
    next_id = 1
    for i in range(1, labels.max()+1):
        if keep[i]:
            out[labels == i] = next_id
            next_id += 1
    return out

# ----------------- core -----------------

def _eval_with_optional_kwargs(model, img2d, **cp_kwargs):
    """Call model.eval with a broad set of kwargs; if TypeError occurs (older/newer API),
    retry with a conservative subset. This keeps script robust across cellpose releases.
    """
    try:
        return model.eval(img2d, **cp_kwargs)
    except TypeError as e:
        # Fallback: keep only the most stable kwargs
        stable_keys = {
            'channel_axis','normalize','invert','diameter','flow_threshold',
            'cellprob_threshold','do_3D','compute_masks'
        }
        slim = {k: v for k, v in cp_kwargs.items() if k in stable_keys}
        warnings.warn(f"Cellpose eval signature mismatch; retrying without optional kwargs. Details: {e}")
        return model.eval(img2d, **slim)

def segment_cellpose(model, img2d, base):
    # Build kwargs for Cellpose v4 eval
    cp_kwargs = dict(
        channel_axis=None,        # 2D grayscale
        normalize=bool(base.get("normalize", True)),
        invert=False,
        diameter=None if not base.get("diameter", 0) else float(base.get("diameter", 0)),
        flow_threshold=float(base.get("flow_threshold", 0.2)),
        cellprob_threshold=float(base.get("cellprob_threshold", -0.5)),
        do_3D=False,
        compute_masks=True,
    )
    # Optional calibrated extras — only attach if present/sensible; _eval_with_optional_kwargs
    # will remove them if not supported by the installed Cellpose version.
    if int(base.get("min_size", 0)) > 0:
        cp_kwargs["min_size"] = int(base.get("min_size", 0))
    # tile_overlap: float in [0,1]; set tile=True to honor overlap in some versions
    if float(base.get("tile_overlap", 0.0)) > 0:
        cp_kwargs["tile_overlap"] = float(base.get("tile_overlap", 0.0))
        # cp_kwargs["tile"] = True
    # niter: either "auto" or int
    niter = base.get("niter", "auto")
    if isinstance(niter, (int, np.integer)) and int(niter) > 0:
        cp_kwargs["niter"] = int(niter)

    # Execute segmentation
    masks, flows, styles = _eval_with_optional_kwargs(model, img2d, **cp_kwargs)
    return masks

def process_row(row, cfg, model, outdir):
    img_in = imread_any(row["slice_path"])
    roi = imread_any(guess_mask_for_slice(row["slice_path"], str(row.get("mask_path",""))).strip()) > 0

    base = cfg["default"].copy()
    group = str(row.get("group",""))
    if group in cfg: base.update(cfg[group])

    labels_img = segment_cellpose(
        model=model,
        img2d=img_in,
        base=base,
    )

    labels_img = labels_img.copy()
    labels_img[~roi] = 0
    labels_img = label(labels_img > 0, connectivity=1)

    # --- Dynamic post-filters ---
    # Merge legacy min/max_area with calibrated min_size / max_size_fraction
    roi_area = int(roi.sum()) if roi.sum() > 0 else 0
    min_area_cfg = int(base.get("min_area", 0))
    min_size_cfg = int(base.get("min_size", 0))
    eff_min_area = max(min_area_cfg, min_size_cfg)

    max_area_cfg = int(base.get("max_area", 0))
    max_frac = float(base.get("max_size_fraction", 0.0))
    eff_max_area = max_area_cfg
    if roi_area and max_frac > 0:
        eff_max_area = max(max_area_cfg, int(max_frac * roi_area))

    labels_img = post_filter_labels(
        labels_img,
        min_area=eff_min_area,
        max_area=eff_max_area,
        eccentricity_max=float(base.get("eccentricity_max", 1.0)),
        solidity_min=float(base.get("solidity_min", 0.0))
    )

    props = regionprops(labels_img)
    cents = np.array([p.centroid for p in props]) if props else np.empty((0,2))
    n = int(len(props))

    coverage = float((labels_img>0).sum()) / float(roi.sum()) if roi.sum() > 0 else 0.0
    disp = convex_hull_ratio(cents, roi)

    stem = os.path.splitext(os.path.basename(row["slice_path"]))[0]
    png_path = os.path.join(outdir, "QC", f"{stem}_qc.png")
    save_qc_overlay(img_in, roi, cents, png_path)
    labels_path = os.path.join(outdir, "labels", f"{stem}_labels.tif")
    io.imsave(labels_path, labels_img.astype(np.uint16), check_contrast=False)

    return {
        "animal": row["animal"],
        "group": row.get("group",""),
        "slice": os.path.basename(row["slice_path"]),
        "n_cells": n,
        "coverage": coverage,
        "dispersion": disp,
        "cellprob_threshold": base.get("cellprob_threshold", -0.5),
        "flow_threshold": base.get("flow_threshold", 0.2),
        "diameter": base.get("diameter", 0),
        # record calibrated extras for provenance
        "min_size": base.get("min_size", 0),
        "max_size_fraction": base.get("max_size_fraction", 0.0),
        "niter": base.get("niter", "auto"),
        "tile_overlap": base.get("tile_overlap", 0.0)
    }, cents

# ----------------- CLI -----------------

def parse_args():
    p = argparse.ArgumentParser()
    p.add_argument('--meta', required=True, help='metadata csv with columns animal,group,slice_path,mask_path')
    p.add_argument('--out', required=True, help='output directory')
    p.add_argument('--config', default=None, help='JSON config path')
    p.add_argument('--jobs', type=int, default=1, help='parallel jobs (use 1 for GPU)')
    p.add_argument('--gpu', action='store_true', help='use GPU if available')
    return p.parse_args()

def main():
    args = parse_args()
    os.makedirs(args.out, exist_ok=True)
    cfg = load_config(args.config)
    meta = pd.read_csv(args.meta)
    records = meta.to_dict("records")

    # --- Timestamped output folder ---
    timestamp = datetime.now().strftime("%y%m%d_%H%M")
    output_dir = os.path.join(args.out, f"DREADDFUL_output_{timestamp}")
    os.makedirs(output_dir, exist_ok=True)
    # subfolders for images
    png_path = os.path.join(output_dir, "QC")
    os.makedirs(png_path, exist_ok=True)
    labels_path = os.path.join(output_dir, "labels")
    os.makedirs(labels_path, exist_ok=True)

    # Build CPv4 model from config (allow alias 'pretrained')
    pm = cfg["default"].get("pretrained_model") or cfg["default"].get("pretrained") or "cpsam"
    model = models.CellposeModel(gpu=args.gpu, pretrained_model=pm)

    rows, cents_records = [], []

    if args.jobs != 1 and HAVE_JOBLIB:
        with tqdm(total=len(records), desc="Segmenting (joblib)") as pbar:
            def worker(rdict):
                rec, cents = process_row(rdict, cfg, model, output_dir)
                pbar.update(1)
                return rec, cents
            out = Parallel(n_jobs=args.jobs, prefer="processes", batch_size=4)(
                delayed(worker)(rd) for rd in records
            )
    else:
        out = []
        for rd in tqdm(records, desc="Segmenting"):
            try:
                out.append(process_row(rd, cfg, model, output_dir))
            except Exception as e:
                rec = {
                    "animal": rd.get("animal",""), "group": rd.get("group",""),
                    "slice": os.path.basename(rd.get("slice_path","")),
                    "n_cells": np.nan, "coverage": np.nan, "dispersion": np.nan,
                    "error": f"{type(e).__name__}: {e}"
                }
                with open(os.path.join(output_dir, "errors.log"), "a", encoding="utf-8") as f:
                    f.write(f"{rec['slice']}: {rec['error']}\n")
                    traceback.print_exc(file=f)
                out.append((rec, np.empty((0,2))))

    for (rec, cents) in out:
        rows.append(rec)
        for yx in cents:
            cents_records.append({
                "animal": rec["animal"], "group": rec["group"], "slice": rec["slice"],
                "y": float(yx[0]), "x": float(yx[1])
            })

    slice_df = pd.DataFrame(rows)
    slice_df.to_csv(os.path.join(output_dir, "slice_metrics.csv"), index=False)
    pd.DataFrame(cents_records).to_csv(os.path.join(output_dir, "centroids.csv"), index=False)

    animal_df = (slice_df.groupby(["animal","group"], dropna=False)
                 .agg(slice_count=("slice","nunique"),
                      n_cells_total=("n_cells","sum"),
                      coverage_mean=("coverage","mean"),
                      dispersion_mean=("dispersion","mean"))
                 .reset_index())
    animal_df.to_csv(os.path.join(output_dir, "animal_metrics.csv"), index=False)

    if len(animal_df):
        if animal_df["group"].nunique() > 1:
            plt.figure()
            animal_df.boxplot(column='coverage_mean', by='group')
            plt.title('DRN coverage by group'); plt.suptitle(''); plt.ylabel('Coverage (fraction)')
            plt.savefig(os.path.join(output_dir, 'coverage_by_group.png'), dpi=300); plt.close()
            plt.figure()
            animal_df.boxplot(column='dispersion_mean', by='group')
            plt.title('Dispersion index by group'); plt.suptitle(''); plt.ylabel('Convex hull / mask area')
            plt.savefig(os.path.join(output_dir, 'dispersion_by_group.png'), dpi=300); plt.close()
        else:
            plt.figure(); slice_df["coverage"].dropna().hist(bins=20)
            plt.title('Coverage distribution'); plt.xlabel('Coverage'); plt.ylabel('Slices')
            plt.savefig(os.path.join(output_dir, 'coverage_hist.png'), dpi=300); plt.close()
            plt.figure(); slice_df["n_cells"].dropna().hist(bins=20)
            plt.title('Cell count distribution'); plt.xlabel('n_cells'); plt.ylabel('Slices')
            plt.savefig(os.path.join(output_dir, 'cellcount_hist.png'), dpi=300); plt.close()

if __name__ == "__main__":
    main()
